{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üîç H·ªá Th·ªëng Nghi√™n C·ª©u Ph√°p Lu·∫≠t Vi·ªát Nam (v2.0)\n",
                "\n",
                "**C·∫≠p nh·∫≠t m·ªõi:**\n",
                "- T√°ch bi·ªát **Retriever Agent** (Tra c·ª©u n·ªôi b·ªô RAG) v√† **Searcher Agent** (Tra c·ª©u Web).\n",
                "- H·ªó tr·ª£ ki·ªÉm tra hi·ªáu l·ª±c vƒÉn b·∫£n theo th·ªùi gian th·ª±c.\n",
                "- B·∫Øt bu·ªôc tr√≠ch d·∫´n chi ti·∫øt (ƒêi·ªÅu, Kho·∫£n, ƒêi·ªÉm).\n",
                "\n",
                "## H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng:\n",
                "1. Ch·∫°y cell **Setup** ƒë·ªÉ kh·ªüi t·∫°o h·ªá th·ªëng\n",
                "2. **Ch·ªçn c∆° s·ªü d·ªØ li·ªáu RAGFlow**\n",
                "3. Nh·∫≠p c√¢u h·ªèi ph√°p l√Ω\n",
                "4. Ch·∫°y cell **Ch·∫°y Nghi√™n C·ª©u**\n",
                "\n",
                "‚ö†Ô∏è **L∆∞u √Ω:** Vui l√≤ng **Restart Kernel** tr∆∞·ªõc khi ch·∫°y n·∫øu b·∫°n v·ª´a c·∫≠p nh·∫≠t code."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 1Ô∏è‚É£ Setup - Kh·ªüi t·∫°o h·ªá th·ªëng"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "import os\n",
                "import asyncio\n",
                "import logging\n",
                "import requests\n",
                "\n",
                "# Add src to path\n",
                "project_root = os.path.dirname(os.path.abspath('.'))\n",
                "if project_root not in sys.path:\n",
                "    sys.path.insert(0, os.getcwd())\n",
                "\n",
                "# Set logging level\n",
                "logging.basicConfig(level=logging.WARNING, format='%(asctime)s - %(levelname)s - %(message)s')\n",
                "\n",
                "# Load environment variables\n",
                "from dotenv import load_dotenv, find_dotenv\n",
                "load_dotenv(find_dotenv(), override=True)\n",
                "\n",
                "# Import AutoGen components\n",
                "from autogen_agentchat.teams import RoundRobinGroupChat\n",
                "from autogen_agentchat.conditions import TextMentionTermination, MaxMessageTermination\n",
                "from autogen_agentchat.ui import Console\n",
                "\n",
                "# Import our modules\n",
                "from src.config import get_model_client\n",
                "from src.agents.planner import create_planner_agent\n",
                "from src.agents.retriever import create_retriever_agent\n",
                "from src.agents.searcher import create_searcher_agent\n",
                "from src.agents.analyzer import create_analyzer_agent\n",
                "from src.agents.critic import create_critic_agent\n",
                "from src.agents.synthesizer import create_synthesizer_agent\n",
                "from src.tools import set_knowledge_ids, get_knowledge_ids\n",
                "\n",
                "print(\"‚úÖ ƒê√£ import th√†nh c√¥ng t·∫•t c·∫£ modules!\")\n",
                "\n",
                "# Initialize model client\n",
                "try:\n",
                "    model_client = get_model_client()\n",
                "    print(\"‚úÖ ƒê√£ k·∫øt n·ªëi v·ªõi AI model!\")\n",
                "except Exception as e:\n",
                "    print(f\"‚ùå L·ªói k·∫øt n·ªëi model: {e}\")\n",
                "    model_client = None\n",
                "\n",
                "# Create agents\n",
                "if model_client:\n",
                "    planner = create_planner_agent(model_client)\n",
                "    retriever = create_retriever_agent(model_client)\n",
                "    searcher = create_searcher_agent(model_client)\n",
                "    analyzer = create_analyzer_agent(model_client)\n",
                "    critic = create_critic_agent(model_client)\n",
                "    synthesizer = create_synthesizer_agent(model_client)\n",
                "    print(\"‚úÖ ƒê√£ kh·ªüi t·∫°o t·∫•t c·∫£ agents: Planner, Retriever, Searcher, Analyzer, Critic, Synthesizer!\")\n",
                "    print(\"\\nüéØ H·ªá th·ªëng s·∫µn s√†ng! Ti·∫øp t·ª•c ch·ªçn c∆° s·ªü d·ªØ li·ªáu.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 2Ô∏è‚É£ Ch·ªçn C∆° S·ªü D·ªØ Li·ªáu RAGFlow\n",
                "\n",
                "Ch·∫°y cell d∆∞·ªõi ƒë√¢y ƒë·ªÉ ch·ªçn dataset."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import ipywidgets as widgets\n",
                "from IPython.display import display, clear_output\n",
                "\n",
                "def get_ragflow_datasets():\n",
                "    \"\"\"Fetch list of available datasets from RAGFlow.\"\"\"\n",
                "    base_url = os.getenv('RAGFLOW_BASE_URL', 'http://localhost:9380')\n",
                "    api_key = os.getenv('RAGFLOW_API_KEY')\n",
                "    try:\n",
                "        url = f\"{base_url}/api/v1/datasets\"\n",
                "        headers = {'Authorization': f'Bearer {api_key}'}\n",
                "        response = requests.get(url, headers=headers, timeout=5)\n",
                "        data = response.json()\n",
                "        if data.get('code') == 0:\n",
                "            return data.get('data', [])\n",
                "        return []\n",
                "    except:\n",
                "        return []\n",
                "\n",
                "datasets = get_ragflow_datasets()\n",
                "print(f\"üìö T√¨m th·∫•y {len(datasets)} datasets:\\n\")\n",
                "options = []\n",
                "for d in datasets:\n",
                "    label = f\"{d.get('name')} ({d.get('document_count')} docs)\"\n",
                "    print(f\"  ‚Ä¢ {label}\")\n",
                "    options.append((label, d.get('id')))\n",
                "\n",
                "if options:\n",
                "    dropdown = widgets.Dropdown(options=options, description='Dataset:')\n",
                "    btn = widgets.Button(description='‚úì X√°c nh·∫≠n', button_style='success')\n",
                "    out = widgets.Output()\n",
                "    def on_click(b):\n",
                "        with out:\n",
                "            clear_output()\n",
                "            set_knowledge_ids([dropdown.value])\n",
                "            print(f\"‚úÖ ƒê√£ ch·ªçn ID: {dropdown.value}\")\n",
                "    btn.on_click(on_click)\n",
                "    display(widgets.HBox([dropdown, btn]), out)\n",
                "else:\n",
                "    print(\"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y datasets ho·∫∑c l·ªói k·∫øt n·ªëi.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 3Ô∏è‚É£ Nh·∫≠p c√¢u h·ªèi ph√°p l√Ω"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ========================================\n",
                "# üìù NH·∫¨P C√ÇU H·ªéI C·ª¶A B·∫†N T·∫†I ƒê√ÇY:\n",
                "# ========================================\n",
                "\n",
                "query = \"Quy ƒë·ªãnh t√°ch d·ª± √°n ƒë·∫ßu t∆∞\"\n",
                "print(f\"üìã C√¢u h·ªèi: {query}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 4Ô∏è‚É£ Ch·∫°y Nghi√™n C·ª©u (Update Multi-Agent)\n",
                "\n",
                "H·ªá th·ªëng s·∫Ω ch·∫°y v·ªõi quy tr√¨nh:\n",
                "1. **Planner**: L·∫≠p k·∫ø ho·∫°ch.\n",
                "2. **Retriever**: L·∫•y vƒÉn b·∫£n t·ª´ RAG.\n",
                "3. **Searcher**: Check hi·ªáu l·ª±c online.\n",
                "4. **Analyzer**: Ph√¢n t√≠ch & Tr√≠ch d·∫´n.\n",
                "5. **Critic**: Ki·ªÉm duy·ªát.\n",
                "6. **Synthesizer**: T·ªïng h·ª£p b√°o c√°o."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def extract_research_context(result):\n",
                "    \"\"\"Extract text content from research result to pass to synthesizer.\"\"\"\n",
                "    context_parts = []\n",
                "    if not result or not hasattr(result, 'messages'): return \"\"\n",
                "    for msg in result.messages:\n",
                "        source = getattr(msg, 'source', 'Unknown')\n",
                "        content = getattr(msg, 'content', None)\n",
                "        if content:\n",
                "            if isinstance(content, str):\n",
                "                context_parts.append(f\"=== {source} ===\\n{content}\")\n",
                "            elif isinstance(content, list):\n",
                "                for part in content:\n",
                "                    if hasattr(part, 'content'):\n",
                "                        context_parts.append(f\"=== {source} (Tool Result) ===\\n{str(part.content)[:3000]}\")\n",
                "    return \"\\n\\n\".join(context_parts)\n",
                "\n",
                "async def run_legal_research(query: str):\n",
                "    print(\"=\"*60)\n",
                "    print(\"üöÄ B·∫ÆT ƒê·∫¶U NGHI√äN C·ª®U PH√ÅP LU·∫¨T (MULTI-AGENT)\")\n",
                "    print(\"=\"*60)\n",
                "    \n",
                "    # === PHASE 1: Research & Critique ===\n",
                "    print(\"\\nüìö GIAI ƒêO·∫†N 1: NGHI√äN C·ª®U V√Ä ƒê√ÅNH GI√Å\")\n",
                "    print(\"Agents: Planner ‚Üí Retriever ‚Üí Searcher ‚Üí Analyzer ‚Üí Critic\")\n",
                "    print(\"-\"*60)\n",
                "    \n",
                "    research_termination = TextMentionTermination(\"APPROVE\") | MaxMessageTermination(max_messages=15)\n",
                "    \n",
                "    # Added 'searcher' to the team\n",
                "    research_team = RoundRobinGroupChat(\n",
                "        participants=[planner, retriever, searcher, analyzer, critic],\n",
                "        termination_condition=research_termination,\n",
                "    )\n",
                "    \n",
                "    task = f\"Legal Query: {query}\\nPlease plan, retrieve internal docs, verify validity online, and analyze.\"\n",
                "    research_result = await Console(research_team.run_stream(task=task))\n",
                "    \n",
                "    # === PHASE 2: Synthesis ===\n",
                "    print(\"\\nüìù GIAI ƒêO·∫†N 2: T·ªîNG H·ª¢P B√ÅO C√ÅO\")\n",
                "    research_context = extract_research_context(research_result)\n",
                "    \n",
                "    synthesis_team = RoundRobinGroupChat(\n",
                "        participants=[synthesizer],\n",
                "        termination_condition=MaxMessageTermination(max_messages=2),\n",
                "    )\n",
                "    \n",
                "    synthesis_task = f\"\"\"B·∫°n ƒë∆∞·ª£c giao nhi·ªám v·ª• t·ªïng h·ª£p b√°o c√°o ph√°p l√Ω t·ª´ k·∫øt qu·∫£ nghi√™n c·ª©u d∆∞·ªõi ƒë√¢y.\n",
                "\n",
                "=== C√ÇU H·ªéI ===\n",
                "{query}\n",
                "\n",
                "=== K·∫æT QU·∫¢ NGHI√äN C·ª®U ===\n",
                "{research_context}\n",
                "\n",
                "=== Y√äU C·∫¶U ===\n",
                "T·∫°o b√°o c√°o ph√°p l√Ω chi ti·∫øt v·ªõi:\n",
                "1. T√≥m t·∫Øt v·∫•n ƒë·ªÅ\n",
                "2. C∆° s·ªü ph√°p l√Ω (Tr√≠ch d·∫´n c·ª• th·ªÉ ƒêi·ªÅu, Kho·∫£n, ƒêi·ªÉm)\n",
                "3. Ph√¢n t√≠ch hi·ªáu l·ª±c (D·ª±a tr√™n check c·ªßa Searcher)\n",
                "4. K·∫øt lu·∫≠n\n",
                "\n",
                "Vi·∫øt b√°o c√°o ngay.\"\"\"\n",
                "    \n",
                "    synthesis_result = await Console(synthesis_team.run_stream(task=synthesis_task))\n",
                "    print(\"\\n‚úÖ HO√ÄN TH√ÄNH\")\n",
                "    return research_result, synthesis_result\n",
                "\n",
                "# Run\n",
                "if model_client:\n",
                "    research_result, synthesis_result = await run_legal_research(query)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## üìÑ Xu·∫•t B√°o C√°o Cu·ªëi C√πng"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from IPython.display import display, Markdown\n",
                "if 'synthesis_result' in dir() and hasattr(synthesis_result, 'messages'):\n",
                "    for msg in reversed(synthesis_result.messages):\n",
                "        if 'Synthesizer' in getattr(msg, 'source', ''):\n",
                "            display(Markdown(getattr(msg, 'content', '')))\n",
                "            break"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.11.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}